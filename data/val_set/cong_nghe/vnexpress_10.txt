EMO (Emotive Portrait Alive) của Alibaba được xem là bước tiến mới của AI tạo sinh khi "hô biến" hình ảnh bất kỳ có thể nói, hát như thật.  Được nghiên cứu bởi Viện Điện toán Thông minh (IIC) của Alibaba với các tác giả LinRui Tian, Qi Wang, Bang Zhang và LieFeng Bo, EMO có khả năng "tạo biểu cảm kèm âm thanh từ nhân vật trong ảnh". Nói cách khác, AI có thể biến một hình ảnh tham chiếu tĩnh và âm thanh giọng nói thành một video có thể nói, hát với biểu cảm tự nhiên. Một số video được EMO tạo từ ảnh do Alibaba công bố. Video: YouTube/Rinki So với các AI trước đây chỉ làm biến đổi miệng và một phần khuôn mặt, EMO có thể tạo nét mặt, tư thế, di chuyển phần lông mày, nhíu mắt hay thậm chí lắc lư theo điệu nhạc. Đặc biệt, phần miệng được AI thể hiện tự nhiên, đồng bộ môi chính xác. Trong một số video do Alibaba công bố, hình ảnh sẽ biến thành video và hát các bài được nhập vào nhanh chóng. Bên cạnh tiếng Anh và tiếng Trung, EMO cũng hỗ trợ nhiều ngôn ngữ khác. Alibaba cho biết đã huấn luyện AI với một lượng lớn dữ liệu về hình ảnh, âm thanh và video nhằm tạo biểu cảm khuôn mặt một cách chân thực thông qua mô hình khuếch tán riêng có tên Audio2Video. "Chúng tôi muốn giải quyết thách thức lớn hiện nay là tính chân thực và tính biểu cảm trong việc tạo video từ hình ảnh và âm thanh bằng cách tập trung vào mối liên hệ cũng như sắc thái giữa tín hiệu âm thanh và chuyển động trên khuôn mặt", đại diện nhóm giải thích. "Phương pháp được áp dụng là tổng hợp, bỏ qua liên kết mô hình 3D trung gian hoặc các điểm mốc trên khuôn mặt, chuyển tiếp khung hình liền mạch và bảo toàn tính nhất quán trong video, mang lại ảnh động có tính biểu cảm cao và sống động như thật". Hiện dữ liệu của EMO đã được công bố trên Github, còn các tài liệu nghiên cứu được đăng trên ArXiv. Alibaba chưa tiết lộ khi nào sẽ phát hành đại trà AI này. Bảo Lâm