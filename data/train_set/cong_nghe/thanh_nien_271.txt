 Sora, một công cụ tạo video AI (trí tuệ nhân tạo) từ văn bản do OpenAI phát triển, đang nhận được nhiều sự quan tâm từ cộng đồng vì lo ngại về các video AI gần như không thể phân biệt.  Nhiều người nêu lên mối lo ngại về cách Sora có thể được sử dụng để phát tán các nội dung deepfake có hại với tốc độ nhanh chóng. Để ngăn những thông tin sai lệch tiềm ẩn có thể xuất phát từ video AI, một số công cụ sau có thể phát hiện ra chúng. Sự xuất hiện của Sora khiến nhiều người lo ngại về video deepfake lan truyền qua mạng AFP Là chuyên gia hàng đầu về hệ thống máy tính, Intel cung cấp các công cụ AI chất lượng để phát hiện và phân tích các video do AI tạo ra. Một trong số đó là chương trình FakeCatcher có khả năng xác định những thay đổi trong lưu lượng máu và chuyển động của mắt trong video, xác định xem đối tượng được ghi lại bởi con người hay do trí tuệ nhân tạo thực hiện. Đây là một công cụ hiệu quả nhờ khả năng phân tích hàng nghìn video ngay lập tức với tỷ lệ chính xác 96%. Với việc các video AI lan truyền không kiểm soát, FakeCatcher là một phương pháp chắc chắn để phát hiện và phản ứng với những video từ Sora nhanh nhất có thể. Một công cụ phát hiện video AI tuyệt vời khác là Sensity, được chứng minh là có thể phát hiện ngay cả những bức ảnh chân thực nhất được chụp từ DALL-E, Stable Diffusion, FaceSwap và Midjourney. Sensity có thể thực hiện điều này thông qua Generative Adversarial Network tận dụng API để phát hiện các tạo phẩm AI trong đa phương tiện. Hiện tại nó có độ chính xác 95%. Vì đã quen thuộc với hệ thống AI của OpenAI nên Sensity cũng dễ dàng phát hiện các video được tạo từ Sora. Microsoft, nhà đầu tư lớn nhất của OpenAI, cũng đang thực hiện các bước để đảm bảo rằng video AI sẽ không dễ dàng bị sử dụng để lan truyền nội dung sai lệch. Video AI Authenticator là bước đầu tiên trong số nhiều bước của công ty để giải quyết vấn đề này. Công cụ AI này hoạt động bằng cách phát hiện những thay đổi về thang độ xám trong video, những điểm khác biệt mà mắt người không thể thực hiện được và chứng minh điểm tin cậy theo thời gian thực. Microsoft kỳ vọng Video AI Authenticator sẽ là một công cụ hiệu quả trong việc chống lại thông tin sai lệch trong cuộc bầu cử tổng thống Mỹ sắp tới, nơi thông tin sai lệch và tin deepfake dự kiến sẽ gia tăng. Hugging Face là một trong những đối thủ cạnh tranh hàng đầu của OpenAI, vì vậy không có gì ngạc nhiên khi họ cũng đang phát triển công cụ giúp mọi người chống lại các video AI thông qua việc phát triển công cụ gọi là "Provenance, Watermarking and Deepfake Detection". Công cụ này hoạt động bằng cách nhúng hình mờ trong đa phương tiện để giúp các nền tảng khác thông báo cho người dùng rằng nó thực sự do AI tạo ra. Dịch vụ hoạt động với các nền tảng truyền thông xã hội nhằm chống lại thông tin sai lệch bởi AI tạo ra ngày càng tăng. Theo công ty, các phương pháp này bao gồm việc gắn hình mờ kỹ thuật số vào video do Sora tạo ra, cũng như các chỉ số khác để cho thấy rằng đó không phải là cảnh quay thực tế được quay ngoài đời thực.