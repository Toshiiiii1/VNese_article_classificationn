 Một loại sâu máy tính mới hoạt động thông qua các dịch vụ AI có khả năng tự nhân bản, gửi thư rác và đánh cắp dữ liệu.  Theo TechNewsSpace, một nhóm nhà nghiên cứu an ninh mạng quốc tế đã tạo ra một loại sâu máy tính có khả năng tự lan truyền giữa các dịch vụ trí tuệ nhân tạo (AI) tạo sinh, đánh cắp dữ liệu và gửi thư rác qua email. Khi các hệ thống AI tạo sinh như ChatGPT và Gemini ngày càng phát triển, chúng được sử dụng rộng rãi để giải quyết các công việc hằng ngày. Tuy nhiên, các nhà nghiên cứu công nghệ an ninh mạng đã quyết định chứng minh các hệ thống này có thể gây ra mối đe dọa, bằng cách tạo ra một kiểu tấn công mới chưa từng tồn tại. Sâu máy tính có thể lây lan qua các dịch vụ AI tạo sinh TECHNEWSSPACE Theo đó, các nhà nghiên cứu đã phát triển một loại sâu máy tính gọi là Morris II, được đặt theo tên của loại sâu máy tính đầu tiên có tên Morris, từng tấn công 6.200 máy tính vào năm 1988, chiếm 10% tổng số máy tính được kết nối với internet vào thời điểm đó. Morris II đã phát động đợt tấn công email vào các trợ lý ảo dựa trên AI tạo sinh, đánh cắp dữ liệu từ email và gửi thư rác, hoàn toàn vượt qua các biện pháp bảo vệ của ChatGPT và Gemini. Mặc dù loại sâu tấn công AI tạo sinh này chưa được phát hiện trong thực tế, nhưng các nhà nghiên cứu đã gửi lời cảnh báo đến các nhà phát triển độc lập, các công ty khởi nghiệp và các công ty công nghệ đều cẩn thận về mối đe dọa này. Để minh họa cách hoạt động của Morris II, các nhà nghiên cứu đã tạo ra một dịch vụ email có thể nhận và gửi tin nhắn bằng AI tạo sinh thông qua việc kết nối với ChatGPT, Gemini và mô hình LlaVA mã nguồn mở. Trong một cuộc tấn công thử nghiệm, các nhà nghiên cứu đã chuẩn bị một email với một lệnh độc hại để tạo ra phản hồi bằng cách sử dụng tìm kiếm internet, trong đó, mô hình ngôn ngữ lớn sẽ tham khảo internet để lấy thêm thông tin. Khi nhận được email như vậy, dịch vụ sẽ gửi yêu cầu tới GPT-4 hoặc Gemini Pro để tạo phản hồi - yêu cầu này sẽ thực hiện việc 'hack AI tạo sinh' và đánh cắp dữ liệu từ email. Phản hồi của AI sẽ chứa dữ liệu bí mật của người dùng, sau đó lây nhiễm các máy chủ mới khi trả lời email và được lưu trữ trong cơ sở dữ liệu của khách hàng mới. Trong thử nghiệm thứ hai, lệnh độc hại sẽ là một tệp hình ảnh, bằng cách đặt lệnh tự nhân bản vào tệp này và gửi email, hành động phát tán hình ảnh quy mô lớn sẽ được kích hoạt (dù chúng có chứa bất kỳ nội dung cực đoan hay độc hại nào). Các nhà nghiên cứu cho biết phương pháp này có thể trích xuất dữ liệu nhạy cảm trong email, như số điện thoại, thẻ tín dụng hoặc số an sinh xã hội. Các tác giả nghiên cứu cho biết những phương pháp tấn công này có thể thực hiện được do lỗi thiết kế kiến trúc trong hệ sinh thái AI. Họ đã thông báo về những rủi ro với Google và OpenAI. Phía OpenAI xác nhận sự tồn tại của mối đe dọa và cho biết đang nỗ lực cải thiện tính ổn định của các hệ thống, trong khi Google từ chối bình luận.